{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical_work.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrBC530gmg5"
      },
      "source": [
        "Let's start with your project: \n",
        "\n",
        "Are you a data scientist? \n",
        "\n",
        "I think you are an awesome a data scientist.\n",
        "\n",
        "### **Problem** \n",
        "**Our goal is to create a predictive model that can answer the following question:**\n",
        "\n",
        "**What kind of people had a better chance of surviving?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob222w_I-2Y6",
        "outputId": "1b056d19-83b6-4a5c-8111-abe0f2c7599a"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go7Pm8Vr9UtZ",
        "outputId": "06d94279-9f2a-4f3f-a417-a0294f21d43e"
      },
      "source": [
        "#For google drive\n",
        "#%%capture\n",
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.3-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikDYXlij7nKP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhBfwzBgioTD"
      },
      "source": [
        "**Data about passengers:**\n",
        "*   Name\n",
        "*   Age\n",
        "*   Gender.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIEH8iZqi-sk"
      },
      "source": [
        "## Install and Import Libraries\n",
        "Let's install PySpark:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj1HhvIOY5Yz"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql.functions import udf"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDp80mG9jmfU"
      },
      "source": [
        "## Build Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttzML9fpjE5a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiqECDzLj1Mg"
      },
      "source": [
        "## Data Loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-hxNggkTqV"
      },
      "source": [
        "You have two datasets: \n",
        "* Train  \n",
        "* Test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-A8M7QmKDJ"
      },
      "source": [
        "Read two datasets: \n",
        "* Train\n",
        "* Test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx2qAccBk15y"
      },
      "source": [
        "train=spark.read.csv('/content/gdrive/MyDrive/spark/train.csv',header=True,inferSchema=True)\n",
        "test=spark.read.csv('/content/gdrive/MyDrive/spark/test.csv',header=True,inferSchema=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj2ANTnWmSCq"
      },
      "source": [
        "Let's work with train dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5mWJR30lNs5"
      },
      "source": [
        "**Confirm if this is a dataframe or not:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEYTePrzk9yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c5e311-bbab-4fe8-d2e3-5115a9a0f578"
      },
      "source": [
        "print(type(train))\n",
        "print(type(test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvLJElPrlT4i"
      },
      "source": [
        "**Show 5 rows.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYwhqvV8lnO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666be620-b261-4b83-96ca-8d74badfc88f"
      },
      "source": [
        "train.show(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QIYVxRXlnnw"
      },
      "source": [
        "**Display schema for the dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcvERiICl1Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7642059d-909f-4a64-b77c-29ade1416d92"
      },
      "source": [
        "train.printSchema()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmE3Wd80l1S6"
      },
      "source": [
        "**Statistical summary:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNY0SItol5Mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30a7187-e404-4f02-d681-24fd804ebfcf"
      },
      "source": [
        "train.describe().show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFaIEQTl70_"
      },
      "source": [
        "## EDA - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSNPOnP8mw2Q"
      },
      "source": [
        "**Display count for the train dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtpG11Fl9HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeae79fb-6187-43fb-b2c6-1f2d551d3ecb"
      },
      "source": [
        "train.count()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_6nnTfxm9_x"
      },
      "source": [
        "**Can you answer this question:** \n",
        "\n",
        "**How many people survived, and how many didn't survive?** \n",
        "\n",
        "**Please save data in a variable.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDoqPwyomYxA"
      },
      "source": [
        "survived=train.select('Survived').where('Survived = 1').count()\n",
        "not_survived=train.select('Survived').where('Survived = 0').count()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8DUtZXPn46m"
      },
      "source": [
        "**Display your result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XHAK8ceoCMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2582afef-d997-4d46-ebff-216c4903f61f"
      },
      "source": [
        "print('number of survived',survived)\n",
        "print('number of people didnt survive',not_survived)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of survived 342\n",
            "number of people didnt survive 549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygsg7wQqor9a"
      },
      "source": [
        "**Can you display your answer in ratio form?(Hint: Use UDF.)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uiaN29PoQnf"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvzEwesgoQ3s"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7Aker_lp1h4"
      },
      "source": [
        "**Can you get the number of males and females?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XllkDlo3ongJ"
      },
      "source": [
        "males=train.select('Sex').where('Sex = \"male\"').count()\n",
        "females=train.select('Sex').where('Sex = \"female\"').count()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoNtgfIi5-jQ",
        "outputId": "4912daf3-2d6e-469c-a0fb-d0d81a865adf"
      },
      "source": [
        "print(males)\n",
        "print(females)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "577\n",
            "314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFaJ15zqtEV"
      },
      "source": [
        "**1. What is the average number of survivors of each gender?**\n",
        "\n",
        "**2. What is the number of survivors of each gender?**\n",
        "\n",
        "(Hint: Group by the \"sex\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUikH7MUqdKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cadbcdf-2246-4e7b-f933-6b04105946a6"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "male_survived = train.groupBy('Sex').agg(F.mean('Survived'))\n",
        "male_survived.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+\n",
            "|   Sex|      avg(Survived)|\n",
            "+------+-------------------+\n",
            "|female| 0.7420382165605095|\n",
            "|  male|0.18890814558058924|\n",
            "+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEdYNdArtRN"
      },
      "source": [
        "**Create temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjlK6HDUqsI5"
      },
      "source": [
        "train.createOrReplaceTempView('TRAIN')\n",
        "test.createOrReplaceTempView('TEST')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXNePifnshHr"
      },
      "source": [
        "**How many people survived, and how many didn't survive? By SQL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HxfPRTMslqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e784f74-8894-42ea-a64f-5fa4ca92e104"
      },
      "source": [
        "spark.sql('select count(Survived) From TRAIN where Survived = 1').show()\n",
        "spark.sql('select count(Survived) From TRAIN where Survived = 0').show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|count(Survived)|\n",
            "+---------------+\n",
            "|            342|\n",
            "+---------------+\n",
            "\n",
            "+---------------+\n",
            "|count(Survived)|\n",
            "+---------------+\n",
            "|            549|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVCdY6EasFWV"
      },
      "source": [
        "**Can you display the number of survivors from each gender as a ratio?**\n",
        "\n",
        "(Hint: Group by \"sex\" column.)\n",
        "\n",
        "**Can you do this via SQL?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xQc3pUUr3HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4b4322-6cd0-45f7-a14e-d0612e99dd4a"
      },
      "source": [
        "spark.sql('select Sex,avg(Survived) From TRAIN group by Sex').show()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+\n",
            "|   Sex|      avg(Survived)|\n",
            "+------+-------------------+\n",
            "|female| 0.7420382165605095|\n",
            "|  male|0.18890814558058924|\n",
            "+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6QXc5V8uu3Y"
      },
      "source": [
        "**Display a ratio for p-class:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mscs2mDFdFsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f51b8e8-0ba1-4b14-a439-31ed5ac5c1bd"
      },
      "source": [
        "spark.sql('select Pclass,count(*) * 100.0/ sum(count(*)) over () as ratio from train group by Pclass').show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------+\n",
            "|Pclass|            ratio|\n",
            "+------+-----------------+\n",
            "|     1|24.24242424242424|\n",
            "|     3|55.10662177328844|\n",
            "|     2|20.65095398428732|\n",
            "+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX0klxwAvg6J"
      },
      "source": [
        "**Let's take a break and continue after this.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ctM9t8atxJl"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CfanZTCt6Wk"
      },
      "source": [
        "**First and foremost, we must merge both the train and test datasets. (Hint: The union function can do this.)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nm8S1K0r4uY"
      },
      "source": [
        "merged_df=train.union(test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI7AD8FLz3iO"
      },
      "source": [
        "**Display count:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rd9e6nzzr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc707e79-7ad7-45d4-db48-9498ccabc5be"
      },
      "source": [
        "merged_df.count()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1329"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVQlr9vDy7Y4"
      },
      "source": [
        "**Temporary view PySpark:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_WERAL8wvJa"
      },
      "source": [
        "merged_df.createOrReplaceTempView('merged')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4Miuy0z_uP"
      },
      "source": [
        "**Can you define the number of null values in each column?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LMOalKBxhpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d04490-8a84-42bd-c080-aeddbd9693bb"
      },
      "source": [
        "nullvalues_df=merged_df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in merged_df.columns]\n",
        "   )\n",
        "nullvalues_df.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|          0|       0|     0|   0|  0|265|    0|    0|     0|   0| 1021|       3|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBX8cJ000aqe"
      },
      "source": [
        "**Create Dataframe for null values**\n",
        "\n",
        "1. Column\n",
        "2. Number of missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITmyUelNxjJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1341b350-4e33-4618-bce4-d487bb33f152"
      },
      "source": [
        "nullvalues_df.select(['Age','Cabin','Embarked']).show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+--------+\n",
            "|Age|Cabin|Embarked|\n",
            "+---+-----+--------+\n",
            "|265| 1021|       3|\n",
            "+---+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKrOi5a0-Ma"
      },
      "source": [
        "## Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txa8NZIO1JaP"
      },
      "source": [
        "**Can you show me the name column from your temporary table?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7yXqJoJy35k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a02212-435c-4332-c6d3-88e727919e0f"
      },
      "source": [
        "spark.sql('select Name from merged').show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                Name|\n",
            "+--------------------+\n",
            "|Braund, Mr. Owen ...|\n",
            "|Cumings, Mrs. Joh...|\n",
            "|Heikkinen, Miss. ...|\n",
            "|Futrelle, Mrs. Ja...|\n",
            "|Allen, Mr. Willia...|\n",
            "|    Moran, Mr. James|\n",
            "|McCarthy, Mr. Tim...|\n",
            "|Palsson, Master. ...|\n",
            "|Johnson, Mrs. Osc...|\n",
            "|Nasser, Mrs. Nich...|\n",
            "|Sandstrom, Miss. ...|\n",
            "|Bonnell, Miss. El...|\n",
            "|Saundercock, Mr. ...|\n",
            "|Andersson, Mr. An...|\n",
            "|Vestrom, Miss. Hu...|\n",
            "|Hewlett, Mrs. (Ma...|\n",
            "|Rice, Master. Eugene|\n",
            "|Williams, Mr. Cha...|\n",
            "|Vander Planke, Mr...|\n",
            "|Masselmani, Mrs. ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F0F9cTZ2Cuz"
      },
      "source": [
        "**Run this code:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kx6OcB-2BBT"
      },
      "source": [
        "combined = merged_df.withColumn('Title',F.regexp_extract(F.col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
        "combined.createOrReplaceTempView('combined')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZeUWS12r59"
      },
      "source": [
        "**Display the title and count \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGkFMtlp1FAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9aed2d-f694-4566-e46d-a5372d33371b"
      },
      "source": [
        "title_df=spark.sql('select Title , count(Title) as counts from combined group by Title')\n",
        "title_df.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|   Title|counts|\n",
            "+--------+------+\n",
            "|     Don|     1|\n",
            "|    Miss|   257|\n",
            "|Countess|     2|\n",
            "|     Col|     4|\n",
            "|     Rev|     9|\n",
            "|    Lady|     2|\n",
            "|  Master|    56|\n",
            "|     Mme|     1|\n",
            "|    Capt|     2|\n",
            "|      Mr|   786|\n",
            "|      Dr|    11|\n",
            "|     Mrs|   186|\n",
            "|     Sir|     2|\n",
            "|Jonkheer|     2|\n",
            "|    Mlle|     4|\n",
            "|   Major|     3|\n",
            "|      Ms|     1|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLBQDKYu4JOa"
      },
      "source": [
        "**We can see that Dr, Rev, Major, Col, Mlle, Capt, Don, Jonkheer, Countess, Ms, Sir, Lady, and Mme are really rare titles, so create Dictionary and set the value to \"rare\".**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjnx5l5r2Qaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c64fce2-a83d-40fd-cb3f-bfae8b912a53"
      },
      "source": [
        "rare_dict={i[0]:'rare' for i in title_df.select('Title').where('counts < 56').collect()}\n",
        "for i in title_df.select('Title').collect():\n",
        "    if i[0] not in rare_dict.keys():\n",
        "        rare_dict[i[0]]=i[0]\n",
        "rare_dict"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Capt': 'rare',\n",
              " 'Col': 'rare',\n",
              " 'Countess': 'rare',\n",
              " 'Don': 'rare',\n",
              " 'Dr': 'rare',\n",
              " 'Jonkheer': 'rare',\n",
              " 'Lady': 'rare',\n",
              " 'Major': 'rare',\n",
              " 'Master': 'Master',\n",
              " 'Miss': 'Miss',\n",
              " 'Mlle': 'rare',\n",
              " 'Mme': 'rare',\n",
              " 'Mr': 'Mr',\n",
              " 'Mrs': 'Mrs',\n",
              " 'Ms': 'rare',\n",
              " 'Rev': 'rare',\n",
              " 'Sir': 'rare'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wrE95Cv7Oqh"
      },
      "source": [
        "**Run the function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdDbWuDl7Pf4"
      },
      "source": [
        "def impute_title(title):\n",
        "    return rare_dict[title]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EQVIhK7a9R"
      },
      "source": [
        "**Apply the function on \"Title\" column using UDF:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBAiIOn77XFa"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "convertUDF = udf(lambda z: impute_title(z))\n",
        "combined=combined.withColumn('Title',convertUDF(F.col('Title')))\n",
        "combined.createOrReplaceTempView('combined')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn8ewllf7kiV"
      },
      "source": [
        "**Display \"Title\" from table and group by \"Title\" column:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9sjQb084GU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c6ef19-1405-4cf6-aba6-103d1b86e4a4"
      },
      "source": [
        "spark.sql('select Title from combined group by Title').show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "| Title|\n",
            "+------+\n",
            "|  rare|\n",
            "|  Miss|\n",
            "|Master|\n",
            "|    Mr|\n",
            "|   Mrs|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H45QNLj9vJp"
      },
      "source": [
        "## **Preprocessing Age**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwRAhumK-u__"
      },
      "source": [
        "**Based on the age mean, you will fill in the missing age values:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXYSVzvl4z63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0a5372-8389-4e4d-b89e-dcd861c5f198"
      },
      "source": [
        "avgAge=spark.sql('select avg(Age) from combined').collect()\n",
        "avgAge[0][0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.079501879699244"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLPivde8_GI-"
      },
      "source": [
        "**Fill missing age with age mean:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBgW8aFD90PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0658a40-0525-40ca-bd87-2d36d4c83a81"
      },
      "source": [
        "combined=combined.fillna(avgAge[0][0],'Age')\n",
        "combined.select('Age').show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|               Age|\n",
            "+------------------+\n",
            "|              22.0|\n",
            "|              38.0|\n",
            "|              26.0|\n",
            "|              35.0|\n",
            "|              35.0|\n",
            "|30.079501879699244|\n",
            "|              54.0|\n",
            "|               2.0|\n",
            "|              27.0|\n",
            "|              14.0|\n",
            "|               4.0|\n",
            "|              58.0|\n",
            "|              20.0|\n",
            "|              39.0|\n",
            "|              14.0|\n",
            "|              55.0|\n",
            "|               2.0|\n",
            "|30.079501879699244|\n",
            "|              31.0|\n",
            "|30.079501879699244|\n",
            "+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsnUz-m_P95"
      },
      "source": [
        "## **Preprocessing Embarked**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHbbamcXMSYP"
      },
      "source": [
        "**Select Embarked, count them, order by count Desc, and save in grouped_Embarked variable:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-lRu5vc_FW7"
      },
      "source": [
        "grouped_Embarked=spark.sql('select Embarked,count(Embarked) as count from combined group by Embarked order by count DESC')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1qf5u2IOQrx"
      },
      "source": [
        "**Show groupped_Embarked:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSFNDTNg_erb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c429702-d98b-40f4-cdc6-4ed1be16e4c8"
      },
      "source": [
        "grouped_Embarked.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Embarked|count|\n",
            "+--------+-----+\n",
            "|       S|  962|\n",
            "|       C|  253|\n",
            "|       Q|  111|\n",
            "|    null|    0|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzQWYgKBMrbp"
      },
      "source": [
        "**Get the groupped_Embarked:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu46QWrn_gCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7df33255-d8cd-416d-f5d9-3ae89a46426b"
      },
      "source": [
        "max_embarked=grouped_Embarked.select('Embarked').collect()[0][0]\n",
        "max_embarked"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'S'"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLYj4F7E_iqb"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vhoEs8N2w_"
      },
      "source": [
        "**Fill missing values with Top 'S' of grouped_Embarked:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdzQCRud_mAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99be4fa5-157d-4111-9d03-3aee757d6ad9"
      },
      "source": [
        "combined=combined.fillna('S','Embarked')\n",
        "combined.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in combined.columns]\n",
        "   ).show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+-----+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|Title|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+-----+\n",
            "|          0|       0|     0|   0|  0|  0|    0|    0|     0|   0| 1021|       0|    0|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEcdV5Vb_qR_"
      },
      "source": [
        "## **Preprocessing Cabin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BQzPs7tqhpA"
      },
      "source": [
        "**Replace \"cabin\" column with first char from the string:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6L5pK0_nQz"
      },
      "source": [
        "@udf(returnType=StringType()) \n",
        "def firstLetter(str):\n",
        "    if str:\n",
        "        return str[0]\n",
        "\n",
        "combined=combined.withColumn(\"Cabin\", firstLetter(F.col(\"Cabin\")))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H8XshnYj4k2"
      },
      "source": [
        "**Show the result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUQwnG1Oj2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7542fce-8955-45d6-ec2f-6c7c7a75e6dc"
      },
      "source": [
        "combined.select('Cabin').show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|Cabin|\n",
            "+-----+\n",
            "| null|\n",
            "|    C|\n",
            "| null|\n",
            "|    C|\n",
            "| null|\n",
            "| null|\n",
            "|    E|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "|    G|\n",
            "|    C|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "| null|\n",
            "+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzSDsWsUj9Im"
      },
      "source": [
        "**Create the temporary view:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7CXTY7_tMJ"
      },
      "source": [
        "combined.createOrReplaceTempView('combined')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv7lfQFkrLlN"
      },
      "source": [
        "**Select \"Cabin\" column, count Cabin column, Group by \"Cabin\" column, Order By count DESC**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0tZG_mvrKXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6fe42f-6a53-41ba-c6f4-1f7a98a3cb8f"
      },
      "source": [
        "spark.sql('select Cabin,count(Cabin) as count from combined group by Cabin order by count DESC').show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|Cabin|count|\n",
            "+-----+-----+\n",
            "|    C|   82|\n",
            "|    B|   77|\n",
            "|    D|   52|\n",
            "|    E|   51|\n",
            "|    A|   23|\n",
            "|    F|   18|\n",
            "|    G|    4|\n",
            "|    T|    1|\n",
            "| null|    0|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GR6j0LOsB4y"
      },
      "source": [
        "**Fill missing values with \"U\":**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwq5CHEz_up_"
      },
      "source": [
        "combined=combined.fillna('U','Cabin')\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRnhA_5-0Hi4"
      },
      "source": [
        "**StringIndexer: A label indexer that maps a string column of labels to an ML column of label indices. If the input column is numeric, we cast it to string and index the string values. The indices are in [0, numLabels). By default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting stringOrderType. Its default value is ‘frequencyDesc’.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIKlOX71GQ-"
      },
      "source": [
        "**StringIndexer(inputCol=None, outputCol=None)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0c_Hf_b0R12"
      },
      "source": [
        "**Pipeline: ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWfXaZ0I4dXD"
      },
      "source": [
        "____________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzFCa54R15-g"
      },
      "source": [
        "**Use Pipline to fit and transform:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reefVB345-je",
        "outputId": "d82b2427-5670-40f4-9fd3-02032faefcaf"
      },
      "source": [
        "combined.printSchema()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = false)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = false)\n",
            " |-- Embarked: string (nullable = false)\n",
            " |-- Title: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNNQTf945-je",
        "outputId": "31d8f0f0-ef11-4b69-9426-e87b7562a73e"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "combined.dtypes"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('PassengerId', 'int'),\n",
              " ('Survived', 'int'),\n",
              " ('Pclass', 'int'),\n",
              " ('Name', 'string'),\n",
              " ('Sex', 'string'),\n",
              " ('Age', 'double'),\n",
              " ('SibSp', 'int'),\n",
              " ('Parch', 'int'),\n",
              " ('Ticket', 'string'),\n",
              " ('Fare', 'double'),\n",
              " ('Cabin', 'string'),\n",
              " ('Embarked', 'string'),\n",
              " ('Title', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhtC8jH_xHE"
      },
      "source": [
        "# stringindexer=StringIndexer(inputCols=)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FsiLsd9452v"
      },
      "source": [
        "**VectorAssembler: VectorAssembler(*, inputCols=None, outputCol=None) A feature transformer that merges multiple columns into a vector column.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8DeZfh7JIo"
      },
      "source": [
        "**Use randomSplit function and split data to x_train, and X_test with 80% and 20% Consecutive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C11xf1iAzKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce95cfdd-b8f0-4966-c74a-a521d721b58f"
      },
      "source": [
        "X_train, X_test = combined.randomSplit([0.8,0.2],seed=0)\n",
        "print(f\"There are {X_train.count()} rows in the training set, and {X_test.count()} in the test set.\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1060 rows in the training set, and 269 in the test set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDAX3S9J5-jg",
        "outputId": "0b927fb9-69bd-4722-b8dc-974e1ca6e7f8"
      },
      "source": [
        "categoricalColumns = [col for (col, dtype) in X_train.dtypes if dtype == \"string\"]\n",
        "categoricalColumns.remove(\"Name\")\n",
        "categoricalColumns.remove(\"Ticket\")\n",
        "categoricalColumns"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex', 'Cabin', 'Embarked', 'Title']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5rgTw2P5-jg",
        "outputId": "17fb006b-11a5-4ac1-84e0-59afe29e75fe"
      },
      "source": [
        "numericColumns = [field for (field,dataType) in X_train.dtypes\n",
        "              if ((dataType=='double'or dataType=='int')& (field!='Survived'))]\n",
        "numericColumns.remove('PassengerId')\n",
        "numericColumns"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqMfMbUZ5-jh",
        "outputId": "777cd53e-2812-4fcf-f2ca-5a1053c701f7"
      },
      "source": [
        "indexOutputColumns = [x + \"_Index\" for x in categoricalColumns]\n",
        "indexOutputColumns"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex_Index', 'Cabin_Index', 'Embarked_Index', 'Title_Index']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgyG-iJ_5-jh",
        "outputId": "a1713d30-d4e9-4c13-ab00-7c77cd6ad2f7"
      },
      "source": [
        "oheOutputColumns = [x + \"_OHE\" for x in categoricalColumns]\n",
        "oheOutputColumns"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex_OHE', 'Cabin_OHE', 'Embarked_OHE', 'Title_OHE']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAJzJNOc5-jh"
      },
      "source": [
        "stringindexer = StringIndexer(inputCols=categoricalColumns,\n",
        "                             outputCols=indexOutputColumns)\n",
        "ohe = OneHotEncoder(inputCols=indexOutputColumns,\n",
        "                          outputCols=oheOutputColumns)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHtGdc5Y5-jh",
        "outputId": "01f7b38e-f050-4faf-da8c-7f0e728bcb2a"
      },
      "source": [
        "vect_assemb_input = oheOutputColumns + numericColumns\n",
        "vect_assemb_input"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex_OHE',\n",
              " 'Cabin_OHE',\n",
              " 'Embarked_OHE',\n",
              " 'Title_OHE',\n",
              " 'Pclass',\n",
              " 'Age',\n",
              " 'SibSp',\n",
              " 'Parch',\n",
              " 'Fare']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF0JpWai5-ji"
      },
      "source": [
        "vecAssembler = VectorAssembler(inputCols=vect_assemb_input,outputCol='features')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJQvmFai72O7"
      },
      "source": [
        "**Build RandomForestClassifier model and use pipeline to fit and transform then display \"prediction, Survived, features\" columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIDSJzgA035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc5b7a5-3c98-434b-c006-00a2c87f4690"
      },
      "source": [
        "rf = RandomForestClassifier(featuresCol='features', labelCol='Survived', predictionCol='prediction')\n",
        "pipeline =Pipeline(stages = [stringindexer,ohe,vecAssembler,rf])\n",
        "model=pipeline.fit(X_train)\n",
        "pred=model.transform(X_test)\n",
        "pred.select('prediction','Survived','features').show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       0.0|       1|(20,[0,5,9,11,15,...|\n",
            "|       1.0|       1|(20,[1,12,15,16,1...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       0.0|       0|(20,[0,1,10,15,16...|\n",
            "|       0.0|       1|(20,[0,1,10,11,15...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       1.0|       1|(20,[1,10,12,15,1...|\n",
            "|       1.0|       0|(20,[1,9,13,15,16...|\n",
            "|       1.0|       1|(20,[1,9,13,15,16...|\n",
            "|       0.0|       0|(20,[0,1,10,11,15...|\n",
            "|       1.0|       1|(20,[3,9,12,15,16...|\n",
            "|       0.0|       0|(20,[0,2,9,11,15,...|\n",
            "|       0.0|       1|(20,[0,1,10,14,15...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       0.0|       0|(20,[0,7,9,11,15,...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       0.0|       0|(20,[0,1,9,11,15,...|\n",
            "|       1.0|       0|(20,[1,9,12,15,16...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSXEI8-r8bKY"
      },
      "source": [
        "**Use MulticlassClassificationEvaluator and set the \"labelCol\" to \"Survived\",  \"predictionCol\" to \"prediction\", \"metricName\" to \"accuracy\"** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl0UAKCaBDO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1924693a-b6da-4a2d-836c-721704dfbab3"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Survived',\n",
        "                                              predictionCol='prediction',\n",
        "                                              metricName='accuracy')\n",
        "print(evaluator.evaluate(pred))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8364312267657993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO6_R1zJ9R1R"
      },
      "source": [
        "**When you are finished send the project via Google classroom**\n",
        "**Please let me know if you have any questions.**\n",
        "* nabieh.mostafa@yahoo.com\n",
        "* +201015197566 (Whatsapp)\n",
        "\n",
        "**Don't Hate me, I push you to learn**\n",
        "\n",
        "**I will help you to become an awesome data engineer.**\n",
        "\n",
        "**Why did I say that \"Data Engineer\"?**\n",
        "\n",
        "**Tricky question, but an optional question, if you would like to know the answer, ask me.**\n"
      ]
    }
  ]
}